import requests
from bs4 import BeautifulSoup
import csv
import sqlite3


url = 'https://www.blogger.com/about/?bpli=1'


response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')


data_to_scrape = soup.findAll('section', attrs={'class': "choose-design active"})


csv_file_name = 'scraped_data.csv'
with open(csv_file_name, mode='w', newline='', encoding='utf-8') as file:
    writer = csv.writer(file)
    writer.writerow(['Header 1', 'Header 2'])  # Adjust according to your data

    for item in data_to_scrape:
        writer.writerow([item.text.strip()])  # Adjust as necessary

print(f'Data has been written to {csv_file_name}')


db_name = 'scraped_data.db'
conn = sqlite3.connect(db_name)
c = conn.cursor()

c.execute('''CREATE TABLE IF NOT EXISTS data_table
             (column1 TEXT, column2 TEXT)''')  # Adjust table schema as needed

for item in data_to_scrape:
    c.execute("INSERT INTO data_table (column1, column2) VALUES (?, ?)",
              (item.text.strip(), 'Another Value'))  # Adjust as necessary

conn.commit()
conn.close()

print(f'Data has been inserted into the database: {db_name}')
